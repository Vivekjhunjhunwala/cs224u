{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.data import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>the rock is destined to be the st century new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>the gorgeously elaborate continuation of the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>singer composer bryan adams contributes slew o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>__label__neutral</td>\n",
       "      <td>you think by now america would have had enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>yet the act is still charming here</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label                                               text\n",
       "0  __label__positive  the rock is destined to be the st century new ...\n",
       "1  __label__positive  the gorgeously elaborate continuation of the l...\n",
       "2  __label__positive  singer composer bryan adams contributes slew o...\n",
       "3   __label__neutral  you think by now america would have had enough...\n",
       "4  __label__positive                 yet the act is still charming here"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_sst.csv\")#.sample(frac=1).drop_duplicates()\n",
    "data = data[['label', 'text']] #.rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
    "\n",
    "data['label'] = '__label__' + data['label'].astype(str)\n",
    "data['text'] = data['text'].astype(str)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>it lovely film with lovely performances by buy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>__label__neutral</td>\n",
       "      <td>no one goes unindicted here which is probably ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>and if you re not nearly moved to tears by cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>warm funny engaging film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>uses sharp humor and insight into human nature...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label                                               text\n",
       "0  __label__positive  it lovely film with lovely performances by buy...\n",
       "1   __label__neutral  no one goes unindicted here which is probably ...\n",
       "2  __label__positive  and if you re not nearly moved to tears by cou...\n",
       "3  __label__positive                           warm funny engaging film\n",
       "4  __label__positive  uses sharp humor and insight into human nature..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev = pd.read_csv(\"dev_sst.csv\") #.sample(frac=1).drop_duplicates()\n",
    "data_dev = data_dev[['label', 'text']] #.rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
    " \n",
    "data_dev['label'] = '__label__' + data_dev['label'].astype(str)\n",
    "data_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>__label__neutral</td>\n",
       "      <td>effective but too tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>emerges as something rare an issue movie that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>__label__neutral</td>\n",
       "      <td>the film provides some great insight into the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>__label__positive</td>\n",
       "      <td>offers that rare combination of entertainment ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label                                               text\n",
       "0   __label__neutral                     effective but too tepid biopic\n",
       "1  __label__positive  if you sometimes like to go to the movies to h...\n",
       "2  __label__positive  emerges as something rare an issue movie that ...\n",
       "3   __label__neutral  the film provides some great insight into the ...\n",
       "4  __label__positive  offers that rare combination of entertainment ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"test_sst.csv\") #.sample(frac=1).drop_duplicates()\n",
    "data_test = data_test[['label', 'text']] #.rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
    " \n",
    "data_test['label'] = '__label__' + data_test['label'].astype(str)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8544, 2)\n",
      "(1101, 2)\n",
      "(2210, 2)\n"
     ]
    }
   ],
   "source": [
    "data.to_csv('train_sst_flair_format.csv', sep='\\t', index = False, header = False)\n",
    "data_dev.to_csv('dev_sst_flair_format.csv', sep='\\t', index = False, header = False)\n",
    "data_test.to_csv('test_sst_flair_format.csv', sep='\\t', index = False, header = False)\n",
    "\n",
    "print(data.shape)\n",
    "print(data_dev.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-25 08:13:11,634 Reading data from .\n",
      "2020-02-25 08:13:11,635 Train: train_sst_flair_format.csv\n",
      "2020-02-25 08:13:11,635 Dev: dev_sst_flair_format.csv\n",
      "2020-02-25 08:13:11,636 Test: test_sst_flair_format.csv\n"
     ]
    }
   ],
   "source": [
    "corpus: Corpus = ClassificationCorpus(Path('./'), \n",
    "                                      test_file = 'test_sst_flair_format.csv',\n",
    "                                      dev_file='dev_sst_flair_format.csv', \n",
    "                                      train_file='train_sst_flair_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-25 08:13:11,710 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8503/8503 [00:02<00:00, 3859.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-25 08:13:13,994 [b'positive', b'neutral', b'negative']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_dict = corpus.make_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = [WordEmbeddings('glove')\n",
    "                  # , FlairEmbeddings('news-forward-fast')\n",
    "                  # , FlairEmbeddings('news-backward-fast')\n",
    "                  , BertEmbeddings('bert-base-uncased'),\n",
    "                  # , FlairEmbeddings('multi-backward')\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, \n",
    "                                            hidden_size=512, \n",
    "                                            reproject_words=True, \n",
    "                                            reproject_words_dimension=256,\n",
    "                                            rnn_type='LSTM',\n",
    "                                           bidirectional = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, multi_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-25 08:18:02,158 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:18:02,160 learning rate finder finished - plot learning_rate.tsv\n",
      "2020-02-25 08:18:02,160 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 7. find learning rate\n",
    "learning_rate_tsv = trainer.find_learning_rate('./', 'learning_rate.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning_rate plots are saved in learning_rate.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8. plot the learning rate finder curve\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_learning_rate(learning_rate_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-25 08:18:02,876 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:18:02,880 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): BertEmbeddings(\n",
      "        (model): BertModel(\n",
      "          (embeddings): BertEmbeddings(\n",
      "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (token_type_embeddings): Embedding(2, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): BertEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): BertPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=3172, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, bidirectional=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=2048, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-02-25 08:18:02,881 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:18:02,883 Corpus: \"Corpus: 8503 train + 1098 dev + 2203 test sentences\"\n",
      "2020-02-25 08:18:02,883 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:18:02,884 Parameters:\n",
      "2020-02-25 08:18:02,885  - learning_rate: \"0.1\"\n",
      "2020-02-25 08:18:02,885  - mini_batch_size: \"32\"\n",
      "2020-02-25 08:18:02,886  - patience: \"3\"\n",
      "2020-02-25 08:18:02,887  - anneal_factor: \"0.5\"\n",
      "2020-02-25 08:18:02,888  - max_epochs: \"5\"\n",
      "2020-02-25 08:18:02,888  - shuffle: \"True\"\n",
      "2020-02-25 08:18:02,889  - train_with_dev: \"False\"\n",
      "2020-02-25 08:18:02,890 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:18:02,890 Model training base path: \".\"\n",
      "2020-02-25 08:18:02,891 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:18:02,892 Device: cuda:0\n",
      "2020-02-25 08:18:02,892 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:18:02,893 Embeddings storage mode: cpu\n",
      "2020-02-25 08:18:02,897 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:18:06,018 epoch 1 - iter 0/266 - loss 1.18133175 - samples/sec: 284.17\n",
      "2020-02-25 08:19:16,260 epoch 1 - iter 26/266 - loss 1.08506070 - samples/sec: 11.95\n",
      "2020-02-25 08:20:29,946 epoch 1 - iter 52/266 - loss 1.03548755 - samples/sec: 11.32\n",
      "2020-02-25 08:21:42,602 epoch 1 - iter 78/266 - loss 1.01957318 - samples/sec: 11.48\n",
      "2020-02-25 08:22:51,694 epoch 1 - iter 104/266 - loss 1.00454984 - samples/sec: 12.07\n",
      "2020-02-25 08:24:01,238 epoch 1 - iter 130/266 - loss 0.98039614 - samples/sec: 11.99\n",
      "2020-02-25 08:25:13,124 epoch 1 - iter 156/266 - loss 0.96377229 - samples/sec: 11.65\n",
      "2020-02-25 08:26:27,838 epoch 1 - iter 182/266 - loss 0.95489059 - samples/sec: 11.16\n",
      "2020-02-25 08:27:39,982 epoch 1 - iter 208/266 - loss 0.94724048 - samples/sec: 11.61\n",
      "2020-02-25 08:28:50,995 epoch 1 - iter 234/266 - loss 0.93108460 - samples/sec: 11.74\n",
      "2020-02-25 08:29:59,879 epoch 1 - iter 260/266 - loss 0.92921261 - samples/sec: 12.11\n",
      "2020-02-25 08:30:12,886 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:30:12,888 EPOCH 1 done: loss 0.9283 - lr 0.1000\n",
      "2020-02-25 08:31:45,468 DEV : loss 0.833103358745575 - score 0.6293\n",
      "2020-02-25 08:31:46,061 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertIntermediate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertPooler. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vjhunjhunwala/.conda/envs/flair/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-25 08:31:49,956 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:31:52,970 epoch 2 - iter 0/266 - loss 0.96310091 - samples/sec: 296.24\n",
      "2020-02-25 08:33:02,270 epoch 2 - iter 26/266 - loss 0.83576711 - samples/sec: 12.11\n",
      "2020-02-25 08:34:16,183 epoch 2 - iter 52/266 - loss 0.81419644 - samples/sec: 11.28\n",
      "2020-02-25 08:35:24,055 epoch 2 - iter 78/266 - loss 0.82145965 - samples/sec: 12.29\n",
      "2020-02-25 08:36:35,868 epoch 2 - iter 104/266 - loss 0.82824258 - samples/sec: 11.66\n",
      "2020-02-25 08:37:47,452 epoch 2 - iter 130/266 - loss 0.83338400 - samples/sec: 11.65\n",
      "2020-02-25 08:38:55,799 epoch 2 - iter 156/266 - loss 0.83845137 - samples/sec: 12.26\n",
      "2020-02-25 08:40:09,762 epoch 2 - iter 182/266 - loss 0.82765215 - samples/sec: 11.28\n",
      "2020-02-25 08:41:24,540 epoch 2 - iter 208/266 - loss 0.82458345 - samples/sec: 11.20\n",
      "2020-02-25 08:42:37,475 epoch 2 - iter 234/266 - loss 0.82280271 - samples/sec: 11.43\n",
      "2020-02-25 08:43:50,181 epoch 2 - iter 260/266 - loss 0.81891339 - samples/sec: 11.47\n",
      "2020-02-25 08:44:03,616 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:44:03,617 EPOCH 2 done: loss 0.8190 - lr 0.1000\n",
      "2020-02-25 08:45:36,474 DEV : loss 0.8868281245231628 - score 0.6166\n",
      "2020-02-25 08:45:37,066 BAD EPOCHS (no improvement): 1\n",
      "2020-02-25 08:45:37,067 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:45:39,983 epoch 3 - iter 0/266 - loss 0.95198083 - samples/sec: 307.68\n",
      "2020-02-25 08:46:49,709 epoch 3 - iter 26/266 - loss 0.81414210 - samples/sec: 11.96\n",
      "2020-02-25 08:48:01,863 epoch 3 - iter 52/266 - loss 0.79382801 - samples/sec: 11.56\n",
      "2020-02-25 08:49:13,219 epoch 3 - iter 78/266 - loss 0.79124860 - samples/sec: 11.69\n",
      "2020-02-25 08:50:24,876 epoch 3 - iter 104/266 - loss 0.79406742 - samples/sec: 11.69\n",
      "2020-02-25 08:51:36,528 epoch 3 - iter 130/266 - loss 0.79974120 - samples/sec: 11.64\n",
      "2020-02-25 08:52:47,345 epoch 3 - iter 156/266 - loss 0.79384689 - samples/sec: 11.82\n",
      "2020-02-25 08:54:01,258 epoch 3 - iter 182/266 - loss 0.79284299 - samples/sec: 11.28\n",
      "2020-02-25 08:55:13,453 epoch 3 - iter 208/266 - loss 0.79031555 - samples/sec: 11.55\n",
      "2020-02-25 08:57:35,828 epoch 3 - iter 260/266 - loss 0.78310252 - samples/sec: 11.56\n",
      "2020-02-25 08:57:48,477 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:57:48,478 EPOCH 3 done: loss 0.7822 - lr 0.1000\n",
      "2020-02-25 08:59:21,671 DEV : loss 0.8787248134613037 - score 0.653\n",
      "2020-02-25 08:59:22,264 BAD EPOCHS (no improvement): 0\n",
      "2020-02-25 08:59:28,970 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 08:59:32,659 epoch 4 - iter 0/266 - loss 0.66167742 - samples/sec: 241.47\n",
      "2020-02-25 09:00:41,689 epoch 4 - iter 26/266 - loss 0.76430541 - samples/sec: 12.08\n",
      "2020-02-25 09:01:51,571 epoch 4 - iter 52/266 - loss 0.77416105 - samples/sec: 12.00\n",
      "2020-02-25 09:03:02,392 epoch 4 - iter 78/266 - loss 0.75437159 - samples/sec: 11.78\n",
      "2020-02-25 09:04:17,816 epoch 4 - iter 104/266 - loss 0.75008643 - samples/sec: 11.10\n",
      "2020-02-25 09:05:33,502 epoch 4 - iter 130/266 - loss 0.74467576 - samples/sec: 11.02\n",
      "2020-02-25 09:06:44,030 epoch 4 - iter 156/266 - loss 0.74734981 - samples/sec: 11.82\n",
      "2020-02-25 09:07:57,157 epoch 4 - iter 182/266 - loss 0.75283685 - samples/sec: 11.45\n",
      "2020-02-25 09:09:06,637 epoch 4 - iter 208/266 - loss 0.75052426 - samples/sec: 12.00\n",
      "2020-02-25 09:10:19,607 epoch 4 - iter 234/266 - loss 0.74357555 - samples/sec: 11.47\n",
      "2020-02-25 09:11:28,077 epoch 4 - iter 260/266 - loss 0.75088513 - samples/sec: 12.18\n",
      "2020-02-25 09:11:41,296 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 09:11:41,297 EPOCH 4 done: loss 0.7504 - lr 0.1000\n",
      "2020-02-25 09:13:14,916 DEV : loss 0.8803169131278992 - score 0.6749\n",
      "2020-02-25 09:13:15,543 BAD EPOCHS (no improvement): 0\n",
      "2020-02-25 09:13:22,300 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 09:13:25,579 epoch 5 - iter 0/266 - loss 0.89634949 - samples/sec: 272.67\n",
      "2020-02-25 09:14:37,513 epoch 5 - iter 26/266 - loss 0.74117747 - samples/sec: 11.66\n",
      "2020-02-25 09:15:50,950 epoch 5 - iter 52/266 - loss 0.70878690 - samples/sec: 11.36\n",
      "2020-02-25 09:16:59,904 epoch 5 - iter 78/266 - loss 0.70312058 - samples/sec: 12.10\n",
      "2020-02-25 09:18:11,327 epoch 5 - iter 104/266 - loss 0.70653545 - samples/sec: 11.72\n",
      "2020-02-25 09:19:23,169 epoch 5 - iter 130/266 - loss 0.71187337 - samples/sec: 11.61\n",
      "2020-02-25 09:20:36,675 epoch 5 - iter 156/266 - loss 0.71241318 - samples/sec: 11.39\n",
      "2020-02-25 09:21:46,468 epoch 5 - iter 182/266 - loss 0.71049662 - samples/sec: 11.95\n",
      "2020-02-25 09:22:59,183 epoch 5 - iter 208/266 - loss 0.71622307 - samples/sec: 11.47\n",
      "2020-02-25 09:24:13,002 epoch 5 - iter 234/266 - loss 0.71665404 - samples/sec: 11.34\n",
      "2020-02-25 09:25:22,869 epoch 5 - iter 260/266 - loss 0.71767166 - samples/sec: 11.94\n",
      "2020-02-25 09:25:34,711 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 09:25:34,712 EPOCH 5 done: loss 0.7190 - lr 0.1000\n",
      "2020-02-25 09:27:07,848 DEV : loss 0.8417828679084778 - score 0.6721\n",
      "2020-02-25 09:27:08,445 BAD EPOCHS (no improvement): 1\n",
      "2020-02-25 09:27:15,098 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-25 09:27:15,099 Testing using best model ...\n",
      "2020-02-25 09:27:15,101 loading file best-model.pt\n",
      "2020-02-25 09:30:24,750 0.6945\t0.6945\t0.6945\n",
      "2020-02-25 09:30:24,751 \n",
      "MICRO_AVG: acc 0.532 - f1-score 0.6945\n",
      "MACRO_AVG: acc 0.4189 - f1-score 0.5252666666666667\n",
      "negative   tp: 787 - fp: 396 - fn: 123 - tn: 897 - precision: 0.6653 - recall: 0.8648 - accuracy: 0.6026 - f1-score: 0.7520\n",
      "neutral    tp: 11 - fp: 17 - fn: 374 - tn: 1801 - precision: 0.3929 - recall: 0.0286 - accuracy: 0.0274 - f1-score: 0.0533\n",
      "positive   tp: 732 - fp: 260 - fn: 176 - tn: 1035 - precision: 0.7379 - recall: 0.8062 - accuracy: 0.6267 - f1-score: 0.7705\n",
      "2020-02-25 09:30:24,751 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.6945,\n",
       " 'dev_score_history': [0.6293, 0.6166, 0.653, 0.6749, 0.6721],\n",
       " 'train_loss_history': [0.9283136976392645,\n",
       "  0.8190442190358513,\n",
       "  0.7822414311699402,\n",
       "  0.7504074902910935,\n",
       "  0.7189613053000959],\n",
       " 'dev_loss_history': [tensor(0.8331, device='cuda:0'),\n",
       "  tensor(0.8868, device='cuda:0'),\n",
       "  tensor(0.8787, device='cuda:0'),\n",
       "  tensor(0.8803, device='cuda:0'),\n",
       "  tensor(0.8418, device='cuda:0')]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train('./', \n",
    "              max_epochs=5,\n",
    "              mini_batch_size = 32,\n",
    "              train_with_dev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-25 09:30:24,766 loading file ./final-model.pt\n",
      "[negative (0.42701229453086853)]\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "from flair.data import Sentence, Token\n",
    "\n",
    "classifier = TextClassifier.load('./final-model.pt')\n",
    "sentence = Sentence('A movie worth watching but not for kids')\n",
    "classifier.predict(sentence)\n",
    "print(sentence.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-25 09:30:26,215 loading file ./final-model.pt\n",
      "[negative (0.42701229453086853)]\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier.load('./final-model.pt')\n",
    "sentence = Sentence('A movie worth watching but not for kids')\n",
    "classifier.predict(sentence)\n",
    "print(sentence.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative (0.42701229453086853)\n"
     ]
    }
   ],
   "source": [
    "print(sentence.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_test_results = data_test\n",
    "data_test_results['predicted'] = np.NaN\n",
    "\n",
    "for idx, row in data_test.iterrows():\n",
    "    sentence = Sentence(row['text'])\n",
    "    classifier.predict(sentence)\n",
    "    data_test_results.at[idx, 'predicted'] = sentence.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                          __label__neutral\n",
       "text             effective but too tepid biopic\n",
       "predicted        negative (0.41626760363578796)\n",
       "label_new                               neutral\n",
       "predicted_new                          negative\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                          __label__neutral\n",
       "text             effective but too tepid biopic\n",
       "predicted        negative (0.41626760363578796)\n",
       "label_new                               neutral\n",
       "predicted_new                          negative\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_results['label_new'] = data_test_results['label'].str.replace(\"__label__\", \"\")\n",
    "import re\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "for idx, row in data_test_results.iterrows():\n",
    "    data_test_results.at[idx, 'predicted_new'] = regex.sub('', str(row['predicted']))\n",
    "data_test_results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.87      0.74       912\n",
      "     neutral       0.52      0.03      0.06       389\n",
      "    positive       0.75      0.80      0.77       909\n",
      "\n",
      "    accuracy                           0.69      2210\n",
      "   macro avg       0.64      0.57      0.53      2210\n",
      "weighted avg       0.67      0.69      0.64      2210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(data_test_results['label_new'],data_test_results['predicted_new']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove Embeddings, Epochs = 5, Test_F1_Macro = 0.459, Test_F1_Micro: 0.6237\n",
    "## Glove,Flair, Flair Embeddings, Epochs = 5, Test_F1_Macro = 0.466, Test_F1_Micro: 0.600\n",
    "## Glove,Bert base Embeddings, Epochs = 5, Test_F1_Macro = 0.52, Test_F1_Micro: 0.63\n",
    "## Glove, Bert Base Embeddings, Bidirectional, Epochs = 5, Test_F1_Macro = 0.53, Test_F1_Micro: 0.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'label_dictionary = []\\nlen_label_dict = []\\ntext_dictionary = []\\nlen_text_dict = []\\nfor i in range(len(data)):\\n    #if label==\"\" :\\n    #    print(\\'null\\')\\n    label_dictionary.append(data.loc[i,\\'label\\'])\\n    text_dictionary.append(data.loc[i,\\'text\\'])\\n    len_label_dict.append(len(data.loc[i,\\'label\\']))\\n    len_text_dict.append(len(data.loc[i,\\'text\\']))\\n    if(len(data.loc[i,\\'text\\']) == 1):\\n        print(i)\\nlen(label_dictionary)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"label_dictionary = []\n",
    "len_label_dict = []\n",
    "text_dictionary = []\n",
    "len_text_dict = []\n",
    "for i in range(len(data)):\n",
    "    #if label==\"\" :\n",
    "    #    print('null')\n",
    "    label_dictionary.append(data.loc[i,'label'])\n",
    "    text_dictionary.append(data.loc[i,'text'])\n",
    "    len_label_dict.append(len(data.loc[i,'label']))\n",
    "    len_text_dict.append(len(data.loc[i,'text']))\n",
    "    if(len(data.loc[i,'text']) == 1):\n",
    "        print(i)\n",
    "len(label_dictionary)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame({'labels':label_dictionary,'length':len_label_dict,'text':text_dictionary,'length_text':len_text_dict}).to_csv('lengths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#document_embeddings = document_embeddings.to(flair.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-flair] *",
   "language": "python",
   "name": "conda-env-.conda-flair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
